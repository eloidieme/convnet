{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/eloidieme/dev/python-projects/convnet\n"
     ]
    }
   ],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from cnnClassifier.data.make_dataset import DataLoader\n",
    "\n",
    "np.random.seed(400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load = DataLoader()\n",
    "data = load.make_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = np.load('data/train_val_data.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_file['X_train']\n",
    "Y_train = data_file['Y_train']\n",
    "y_train = data_file['y_train']\n",
    "X_val = data_file['X_val']\n",
    "Y_val = data_file['Y_val']\n",
    "y_val = data_file['y_val']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = 5  # number of filters at layer 1\n",
    "k1 = 5  # width of the filters at layer 1 (final shape: d x k1)\n",
    "n2 = 5  # number of filters at layer 2\n",
    "k2 = 5  # width of the filters at layer 1 (final shape: d x k2)\n",
    "eta = 0.001  # learning rate\n",
    "rho = 0.9  # momentum term\n",
    "\n",
    "d = load.meta['dimensionality']  # dimensionality\n",
    "K = load.meta['n_classes']  # number of classes\n",
    "n_len = load.meta['n_len']  # max len of a name\n",
    "\n",
    "n_len1 = n_len - k1 + 1\n",
    "n_len2 = n_len1 - k2 + 1\n",
    "\n",
    "f_size = n2 * n_len2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE HE INIT FOR SIGMAS\n",
    "sigma1 = 0.3\n",
    "sigma2 = 0.3\n",
    "sigma3 = 0.3\n",
    "\n",
    "F = []\n",
    "F.append(np.random.normal(0.0, sigma1, (d, k1, n1)))\n",
    "F.append(np.random.normal(0.0, sigma2, (n1, k2, n2)))\n",
    "W = np.random.normal(0.0, sigma3, (K, f_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(532, 19834)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 19834)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_input = X_train[:,0]\n",
    "x_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_input = np.reshape(x_input, (d, -1))\n",
    "X_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MF matrix implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mf_matrix(F, n_len):\n",
    "    dd, k, nf = F.shape\n",
    "    V_F = []\n",
    "    for i in range(nf):\n",
    "        V_F.append(F[:,:,i].ravel(order='F').T)\n",
    "    V_F = np.array(V_F)\n",
    "    zero_nlen = np.zeros((dd, nf))\n",
    "    kk = n_len - k\n",
    "    Mf = []\n",
    "    for i in range(kk+1):\n",
    "        tup = [zero_nlen.T for _ in range(kk + 1)]\n",
    "        tup[i] = V_F\n",
    "        Mf.append(np.concatenate(tup, axis=1))\n",
    "    Mf = np.concatenate(Mf, axis=0)\n",
    "    return Mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    dd, k, nf = F[i].shape\n",
    "    assert ((n_len-k+1)*nf, n_len*dd) == make_mf_matrix(F[i], n_len).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MX matrix implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mx_matrix(X_input, d, k, nf, n_len):\n",
    "    I_nf = np.eye(nf)\n",
    "    Mx = []\n",
    "    for i in range(n_len - k + 1):\n",
    "        Mx.append(np.kron(I_nf, X_input[:d,i:i+k].ravel(order='F').T))\n",
    "    Mx = np.concatenate(Mx, axis=0)\n",
    "    return Mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 125)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    d, k, nf = F[i].shape\n",
    "    assert ((n_len - k + 1)*nf, k*nf*d) == make_mx_matrix(X_input, d, k, nf, n_len).shape\n",
    "make_mx_matrix(x_input, d, k, nf, n_len).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution matrices test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d, k, nf = F.shape\n",
    "MX = make_mx_matrix(X_input, d, k, nf, n_len)\n",
    "MF = make_mf_matrix(F, n_len)\n",
    "s1 = MX @ np.ravel(F, order='F')\n",
    "s2 = MF @ x_input\n",
    "np.all(s1 == s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5, 5)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X_input\n",
    "x = np.ravel(X, order='F')\n",
    "F = np.random.normal(0, 0.2, (28, 2, 4))\n",
    "MF = make_mf_matrix(F, n_len)\n",
    "d, k, nf = F.shape\n",
    "MX = make_mx_matrix(X, d, k, nf, n_len)\n",
    "MX.shape\n",
    "s1 = MX @ np.ravel(F, order='F')\n",
    "s2 = MF @ x\n",
    "np.all(s1 == s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "##%%timeit\n",
    "##MX = make_mx_matrix(X_input, d, k, nf, n_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "##%%timeit\n",
    "##MF = make_mf_matrix(F[0], n_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "def evaluate_classifier(X_batch, MFs, W):\n",
    "    s1 = MFs[0] @ X_batch\n",
    "    X1_batch = np.maximum(np.zeros_like(s1), s1)\n",
    "    s2 = MFs[1] @ X1_batch\n",
    "    X2_batch = np.maximum(np.zeros_like(s2), s2)\n",
    "    S_batch = W@X2_batch\n",
    "    P_batch = softmax(S_batch)\n",
    "    return X1_batch, X2_batch, P_batch\n",
    "\n",
    "def compute_loss(X_batch, Y_batch, MFs, W):\n",
    "    _, _, P_batch = evaluate_classifier(X_batch, MFs, W)\n",
    "    fact = 1/X_batch.shape[1]\n",
    "    lcross_sum = np.sum(np.diag(-Y_batch.T@np.log(P_batch)))\n",
    "    return fact*lcross_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 19834)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MFs = [make_mf_matrix(F[0], n_len), make_mf_matrix(F[1], n_len1)]\n",
    "_, _, P = evaluate_classifier(X_train, MFs, W)\n",
    "P.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch = X_train[:,:100]\n",
    "Y_batch = Y_train[:,:100]\n",
    "MFs = [make_mf_matrix(F[0], n_len), make_mf_matrix(F[1], n_len1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradients(X_batch, Y_batch, MFs, W):\n",
    "    X1_batch, X2_batch, P_batch = evaluate_classifier(X_batch, MFs, W)\n",
    "    n = X_batch.shape[1]\n",
    "    fact = 1/n\n",
    "    G_batch = -(Y_batch - P_batch)\n",
    "    dW = fact*(G_batch@X2_batch.T)\n",
    "    G_batch = W.T @ G_batch\n",
    "    G_batch = G_batch * (X2_batch > 0)\n",
    "    g_0 = G_batch[:, 0]\n",
    "    x_0 = X1_batch[:, 0]\n",
    "    v = g_0.T @ make_mx_matrix(x_0, n1, k2, n2, n_len1)\n",
    "    dF2 = fact*v\n",
    "    for i in range(1, n):\n",
    "        gi = G_batch[:, i]\n",
    "        xi = X1_batch[:, i]\n",
    "        v = gi.T @ make_mx_matrix(xi, n1, k2, n2, n_len1)\n",
    "        dF2 += fact*v\n",
    "    G_batch = MFs[1].T @ G_batch\n",
    "    G_batch = G_batch * (X1_batch > 0)\n",
    "    g_0 = G_batch[:, 0]\n",
    "    x_0 = X_batch[:, 0]\n",
    "    v = g_0.T @ make_mx_matrix(x_0, d, k1, n1, n_len)\n",
    "    dF1 = fact*v\n",
    "    for i in range(1, n):\n",
    "        gi = G_batch[:, i]\n",
    "        xi = X_batch[:, i]\n",
    "        v = gi.T @ make_mx_matrix(xi, d, k1, n1, n_len)\n",
    "        dF1 += fact*v\n",
    "    return dW, dF1.reshape(d, k1, n1), dF2.reshape(n1, k2, n2)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "ConvNet = {'F': F, 'W': W}\n",
    "MFs = [make_mf_matrix(F[0], n_len), make_mf_matrix(F[1], n_len1)]\n",
    "\n",
    "def NumericalGradient(X_inputs, Ys, ConvNet, h):\n",
    "    try_ConvNet = ConvNet.copy()\n",
    "    Gs = [None] * (len(ConvNet['F']) + 1)  # Create a list to store gradients for each F and W\n",
    "\n",
    "    # Compute gradients for convolutional layers\n",
    "    for l in range(len(ConvNet['F'])):\n",
    "        try_ConvNet['F'][l] = np.array(ConvNet['F'][l], copy=True)\n",
    "        \n",
    "        Gs[l] = np.zeros_like(ConvNet['F'][l])\n",
    "        nf = ConvNet['F'][l].shape[2]\n",
    "        \n",
    "        for i in range(nf):\n",
    "            try_ConvNet['F'][l] = np.array(ConvNet['F'][l], copy=True)\n",
    "            F_try = np.squeeze(ConvNet['F'][l][:, :, i])\n",
    "            G = np.zeros(np.prod(F_try.shape))\n",
    "            \n",
    "            for j in range(len(G)):\n",
    "                F_try1 = np.array(F_try, copy=True)\n",
    "                F_try1.flat[j] = F_try.flat[j] - h\n",
    "                try_ConvNet['F'][l][:, :, i] = F_try1.reshape(F_try.shape)\n",
    "                \n",
    "                l1 = compute_loss(X_inputs, Ys, MFs, try_ConvNet['W'])\n",
    "                \n",
    "                F_try2 = np.array(F_try, copy=True)\n",
    "                F_try2.flat[j] = F_try.flat[j] + h\n",
    "                try_ConvNet['F'][l][:, :, i] = F_try2.reshape(F_try.shape)\n",
    "                \n",
    "                l2 = compute_loss(X_inputs, Ys, MFs, try_ConvNet['W'])\n",
    "                \n",
    "                G[j] = (l2 - l1) / (2 * h)\n",
    "                try_ConvNet['F'][l][:, :, i] = F_try  # Reset to original F\n",
    "            \n",
    "            Gs[l][:, :, i] = G.reshape(F_try.shape)\n",
    "    \n",
    "    # Compute the gradient for the fully connected layer\n",
    "    W_try = ConvNet['W']\n",
    "    G = np.zeros(np.prod(W_try.shape))\n",
    "    for j in range(len(G)):\n",
    "        W_try1 = np.array(W_try, copy=True)\n",
    "        W_try1.flat[j] = W_try.flat[j] - h\n",
    "        try_ConvNet['W'] = W_try1\n",
    "        \n",
    "        l1 = compute_loss(X_inputs, Ys, MFs, try_ConvNet['W'])\n",
    "        \n",
    "        W_try2 = np.array(W_try, copy=True)\n",
    "        W_try2.flat[j] = W_try.flat[j] + h\n",
    "        try_ConvNet['W'] = W_try2\n",
    "        \n",
    "        l2 = compute_loss(X_inputs, Ys, MFs, try_ConvNet)\n",
    "        \n",
    "        G[j] = (l2 - l1) / (2 * h)\n",
    "        try_ConvNet['W'] = W_try  # Reset to original W\n",
    "    \n",
    "    Gs[-1] = G.reshape(W_try.shape)\n",
    "    \n",
    "    return Gs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
