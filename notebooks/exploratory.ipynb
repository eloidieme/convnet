{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/eloidieme/dev/python-projects/convnet\n"
     ]
    }
   ],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from cnnClassifier.data.make_dataset import DataLoader\n",
    "\n",
    "np.random.seed(400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load = DataLoader()\n",
    "data = load.make_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = np.load('data/train_val_data.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_file['X_train']\n",
    "Y_train = data_file['Y_train']\n",
    "y_train = data_file['y_train']\n",
    "X_val = data_file['X_val']\n",
    "Y_val = data_file['Y_val']\n",
    "y_val = data_file['y_val']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = 2  # number of filters at layer 1\n",
    "k1 = 2  # width of the filters at layer 1 (final shape: d x k1)\n",
    "n2 = 2  # number of filters at layer 2\n",
    "k2 = 2  # width of the filters at layer 1 (final shape: d x k2)\n",
    "eta = 0.001  # learning rate\n",
    "rho = 0.9  # momentum term\n",
    "\n",
    "d = load.meta['dimensionality']  # dimensionality\n",
    "K = load.meta['n_classes']  # number of classes\n",
    "n_len = load.meta['n_len']  # max len of a name\n",
    "\n",
    "n_len1 = n_len - k1 + 1\n",
    "n_len2 = n_len1 - k2 + 1\n",
    "\n",
    "f_size = n2 * n_len2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.01  # density of non-zero elements in X_input\n",
    "sigma1 = np.sqrt(2/(p*d*k1*n1))\n",
    "sigma2 = np.sqrt(2/(n1*k2*n2))\n",
    "sigma3 = np.sqrt(2/f_size)\n",
    "\n",
    "F = []\n",
    "F.append(np.random.normal(0.0, sigma1, (d, k1, n1)))\n",
    "F.append(np.random.normal(0.0, sigma2, (n1, k2, n2)))\n",
    "W = np.random.normal(0.0, sigma3, (K, f_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(532, 19834)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 19834)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = X_train[:, 0]\n",
    "X_input = x_input.reshape((-1, n_len), order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011278195488721804"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_zero_count = np.count_nonzero(X_input)\n",
    "total_elements = X_input.size\n",
    "p = (non_zero_count / total_elements)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MF matrix implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mf_matrix(F, n_len):\n",
    "    dd, k, nf = F.shape\n",
    "    V_F = []\n",
    "    for i in range(nf):\n",
    "        V_F.append(F[:,:,i].flatten(order='F'))\n",
    "    V_F = np.array(V_F)\n",
    "    zero_nlen = np.zeros((dd, nf))\n",
    "    kk = n_len - k\n",
    "    Mf = []\n",
    "    for i in range(kk+1):\n",
    "        tup = [zero_nlen.T for _ in range(kk + 1)]\n",
    "        tup[i] = V_F\n",
    "        Mf.append(np.concatenate(tup, axis=1))\n",
    "    Mf = np.concatenate(Mf, axis=0)\n",
    "    return Mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_lens = [n_len, n_len1]\n",
    "for i in range(2):\n",
    "    dd, k, nf = F[i].shape\n",
    "    assert ((n_lens[i]-k+1)*nf, n_lens[i]*dd) == make_mf_matrix(F[i], n_lens[i]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MX matrix implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mx_matrix(x_input, d, k, nf, n_len):\n",
    "    X_input = x_input.reshape((-1, n_len), order='F')\n",
    "    I_nf = np.eye(nf)\n",
    "    Mx = []\n",
    "    for i in range(n_len - k + 1):\n",
    "        Mx.append(np.kron(I_nf, X_input[:d,i:i+k].ravel(order='F').T))\n",
    "    Mx = np.concatenate(Mx, axis=0)\n",
    "    return Mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "d, k, nf = F[0].shape\n",
    "assert ((n_len - k + 1)*nf, k*nf*d) == make_mx_matrix(X_input, d, k, nf, n_len).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution Matrix Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.33155483 -0.84027707  1.65064729]\n",
      "[-0.33155483 -0.84027707  1.65064729]\n",
      "[-0.33155483 -0.84027707  1.65064729]\n",
      "[-0.33155483 -0.84027707  1.65064729]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(400)\n",
    "X_t = np.random.standard_normal((4, 4))\n",
    "F_t = np.random.standard_normal((4, 2, 1))\n",
    "from scipy.signal import convolve2d\n",
    "\n",
    "s1 = convolve2d(X_t, np.flip(F_t[:,:,0]), mode='valid')[0]\n",
    "s2 = []\n",
    "for i in range(3):\n",
    "    s2.append(X_t[:, i:i+2].flatten() @ F_t[:,:,0].flatten())\n",
    "s2 = np.array(s2)\n",
    "mf = make_mf_matrix(F_t, 4)\n",
    "s3 = mf @ X_t.flatten(order='F')\n",
    "d, k, nf = F_t.shape\n",
    "mx = make_mx_matrix(X_t.flatten(order='F'), d, k, nf, 4)\n",
    "s4 = mx @ F_t[:,:,0].flatten(order='F')\n",
    "print(s1, s2, s3, s4, sep='\\n')\n",
    "assert np.allclose(s1, s2) and np.allclose(s2, s3) and np.allclose(s3, s4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "d, k, nf = F[0].shape\n",
    "MX = make_mx_matrix(x_input, d, k, nf, n_len)\n",
    "MF = make_mf_matrix(F[0], n_len)\n",
    "s1 = MX @ F[0].flatten(order='F')\n",
    "s2 = MF @ x_input\n",
    "assert np.allclose(s1, s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "def evaluate_classifier(X_batch, MFs, W):\n",
    "    s1 = MFs[0] @ X_batch\n",
    "    X1_batch = np.maximum(np.zeros_like(s1), s1)\n",
    "    s2 = MFs[1] @ X1_batch\n",
    "    X2_batch = np.maximum(np.zeros_like(s2), s2)\n",
    "    S_batch = W @ X2_batch\n",
    "    P_batch = softmax(S_batch)\n",
    "    return X1_batch, X2_batch, P_batch\n",
    "\n",
    "def compute_loss(X_batch, Y_batch, F, W):\n",
    "    MFs = [make_mf_matrix(F[0], n_len), make_mf_matrix(F[1], n_len1)]\n",
    "    _, _, P_batch = evaluate_classifier(X_batch, MFs, W)\n",
    "    fact = 1/X_batch.shape[1]\n",
    "    lcross_sum = np.sum(np.diag(-Y_batch.T@np.log(P_batch)))\n",
    "    return fact*lcross_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(532, 100)\n",
      "(36, 100)\n",
      "(34, 100)\n",
      "(18, 100)\n"
     ]
    }
   ],
   "source": [
    "X_batch = X_train[:,:100]\n",
    "Y_batch = Y_train[:,:100]\n",
    "MFs = [make_mf_matrix(F[0], n_len), make_mf_matrix(F[1], n_len1)]\n",
    "X1_batch, X2_batch, P_batch = evaluate_classifier(X_batch, MFs, W)\n",
    "print(X_batch.shape, X1_batch.shape, X2_batch.shape, P_batch.shape, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradients(X_batch, Y_batch, F, W):\n",
    "    MFs = [make_mf_matrix(F[0], n_len), make_mf_matrix(F[1], n_len1)]\n",
    "    dF1 = np.zeros(F[0].size)\n",
    "    dF2 = np.zeros(F[1].size)\n",
    "    X1_batch, X2_batch, P_batch = evaluate_classifier(X_batch, MFs, W)\n",
    "    n = X_batch.shape[1]\n",
    "    fact = 1/n\n",
    "    G_batch = -(Y_batch - P_batch)\n",
    "    dW = fact*(G_batch @ X2_batch.T)\n",
    "    G_batch = W.T @ G_batch\n",
    "    G_batch = G_batch * (X2_batch > 0)\n",
    "    for i in range(n):\n",
    "        gi = G_batch[:, i]\n",
    "        xi = X1_batch[:, i]\n",
    "        v = gi.T @ make_mx_matrix(xi, n1, k2, n2, n_len1)\n",
    "        dF2 += fact*v\n",
    "    G_batch = MFs[1].T @ G_batch\n",
    "    G_batch = G_batch * (X1_batch > 0)\n",
    "    for i in range(n):\n",
    "        gi = G_batch[:, i]\n",
    "        xi = X_batch[:, i]\n",
    "        v = gi.T @ make_mx_matrix(xi, d, k1, n1, n_len)\n",
    "        dF1 += fact*v\n",
    "    return dW, dF1.reshape(F[0].shape, order='F'), dF2.reshape(F[1].shape, order='F')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_gradient_W(X_inputs, Ys, F, W, h):\n",
    "    try_W = np.copy(W)\n",
    "    dW = np.zeros(np.prod(try_W.shape))\n",
    "    for j in range(len(dW)):\n",
    "        W_try1 = np.array(try_W, copy=True)\n",
    "        W_try1.flat[j] = try_W.flat[j] - h\n",
    "        l1 = compute_loss(X_inputs, Ys, F, W_try1)\n",
    "        W_try2 = np.array(try_W, copy=True)\n",
    "        W_try2.flat[j] = try_W.flat[j] + h\n",
    "        l2 = compute_loss(X_inputs, Ys, F, W_try2)\n",
    "        dW[j] = (l2 - l1) / (2 * h)\n",
    "    dW = dW.reshape(try_W.shape)\n",
    "    return dW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_numerical_gradient(compute_loss, X, Y, F_list, W, h = 1e-6):\n",
    "    gradients = []\n",
    "    for F in F_list:\n",
    "        grad = np.zeros_like(F)\n",
    "        it = np.nditer(F, flags=['multi_index'])\n",
    "        while not it.finished:\n",
    "            idx = it.multi_index\n",
    "            orig_val = F[idx]\n",
    "            F[idx] = orig_val + h\n",
    "            fxh1 = compute_loss(X, Y, F_list, W)\n",
    "            F[idx] = orig_val - h\n",
    "            fxh2 = compute_loss(X, Y, F_list, W)\n",
    "            grad[idx] = (fxh1 - fxh2) / (2 * h)\n",
    "            F[idx] = orig_val\n",
    "            it.iternext()\n",
    "        gradients.append(grad)  # Append the gradient of the current array\n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.545332809417605e-10\n",
      "6.564171905684701e-10\n",
      "2.0887783169776242e-10\n"
     ]
    }
   ],
   "source": [
    "dW, dF1, dF2 = compute_gradients(X_batch, Y_batch, F, W)\n",
    "dF1n, dF2n = compute_numerical_gradient(compute_loss, X_batch, Y_batch, F, W)\n",
    "dWn = numerical_gradient_W(X_batch, Y_batch, F, W, 1e-6)\n",
    "print(np.max(np.abs(dW - dWn)), np.max(np.abs(dF1 - dF1n)), np.max(np.abs(dF2 - dF2n)), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_gradient(X_batch, Y_batch, F, W, h=1e-6, eps=1e-10):\n",
    "    _, dF1, dF2 = compute_gradients(X_batch, Y_batch, F, W)\n",
    "    aGrads = [dF1, dF2]\n",
    "    dF1n, dF2n = compute_numerical_gradient(compute_loss, X_batch, Y_batch, F, W, h)\n",
    "    nGrads = [dF1n, dF2n]\n",
    "    rel_errs = []\n",
    "    for k in range(2):\n",
    "        rel_err = np.zeros_like(aGrads[k])\n",
    "        for i in range(rel_err.shape[0]):\n",
    "            for j in range(rel_err.shape[1]):\n",
    "                for l in range(rel_err.shape[2]):\n",
    "                    rel_err[i, j, l] = (np.abs(aGrads[k][i, j, l] - nGrads[k][i, j, l])) / \\\n",
    "                        (max(eps, np.abs(aGrads[k][i, j, l]) +\n",
    "                            np.abs(nGrads[k][i, j, l])))\n",
    "        rel_errs.append(rel_err)\n",
    "    max_diff = [np.max(rel_err) for rel_err in rel_errs]\n",
    "    return max_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.433205641854042e-06, 1.318680221470817e-09]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_gradient(X_batch, Y_batch, F, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
